# Mysql

## 粗略讲解

### 逻辑架构

#### 连接管理与优化

每个连接都会在mysql进程中拥有一个线程，处理这个连接的查询,服务器会负责缓存线程

MySQL会解析查询，并创建内部数据结构 (解析树)，然后对其进行各种优化:包括重写查询、决定表的读取顺序，选择索引等。用户可以通过特殊的关键字提示(hint)优化器影响决策.

### 并发控制

#### 锁的粒度

理论上:只对修改的数据片精确锁定,锁定的数据量越少，则系统的并发程度越高

问题:加锁需要消耗资源。锁的管理:获得锁;检查锁是否已经解除;释放锁  都会增加系统的开销。如果系统花费大量的时间来管理锁，反而影响性能

解决方案: 对锁的颗粒度和管理锁的性能之间获得平衡->常见两种锁 :**表锁 行级锁**

### 事务

#### 隔离级别

- READ UNCOMMITTED (未提交读):

  可以读到事务未提交的数据

  问题:这个数据后续可能还会更改,也可能回滚->**脏读**

- READ COMMITTED(提交读):

  **大多数数据库的默认隔离级别**(**mysql不是**)

  一个事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的

  问题:同一个事物两次重复查询的数据可能不一致->**不可重复读**

- REPEATABLE READ (可重复读)

  同一个事物两次重复查询的数据一致

  问题:范围查询中间可能会插入行->**幻读**,但是InnoDB通过**MVCC**解决了幻读问题

- SERIALIZABLE(可串行化)

  强制事务串行执行,即该事务把读取的每一行都会加锁,会**引起大量超时争用问题**

#### 死锁

为解决死锁问题,会实现各种检测和处理机制,如

1. 检测产生死锁->抛出异常
2. 请求锁超时则放弃锁请求
3. innodb->把持有最少行级锁的事务回滚

#### 事务日志

目前常见修改数据方式

1. 修改数据时,只修改内存中的数据
2. 修改行为记录用**追加**的方式持久到硬盘的事务日志(因此写日志是小块磁盘顺序IO)
3. 后续根据日志把修改的数据刷到磁盘

#### 自动提交

**Mysql默认自动提交**:每个查询都是事务,可通过修改AUTOCOMMIT来改变

有些语句执行前会先强制执行commit提交活动事务:如ALTER TABLE,LOCK TABLE等等

#### 显式隐式锁定

Innodb:**两阶段锁定协议**:随时可以锁定,只有commit/rollback 释放,所有锁同一时间释放

显式锁定语句:

```mysql
SELECT ... LOCK IN SHARE MODE
SELECT ... FOR UPDATE
```

### MVCC

通过保存数据在某个时间点的快照实现,不同存储引擎的 MVCC 实现是不同的，典型的有**乐观** (optimistic)并发控制和**悲观** (pessimistic)并发控制

**特点:**

1. 不管需要执行多长时间，同一个事务看到的数据都是一致的。
2. 根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。

Innodb实现方式:

每行记录后面保存两个隐藏的列:**行的创建时间，行的过期时间 (或删除时间)**。不是实际的时间值，而是系统版本号。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号作为事务的版本号，用来和查询到的每行记录的版本号进行比较

**优点**:大多数读操作不用加锁,性能好

**缺点**:额外存储空间;更多检查工作;更多维护工作

SELECT:

- 只查找版本早于当前事务版本的数据行 (也就是，行的系统版本号小于或等于事务的系统版本号)，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。

- 行的删除版本要么未定义，要么大于当前事务版本号。这可以确保事务读取到的行，在事务开始之前未被删除。

INSERT: InnoDB为新插入的每一行保存当前系统版本号作为行版本号

DELETE: 为删除的每一行保存当前系统版本号作为行删除标识。

UPDATE: 一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。

### 存储引擎:

#### Innodb:

- 默认REPEATABLE READ(可重复读)
- 间隙锁(next-key locking)策略防止幻读的出现:不仅仅锁定查询涉及的行，还会对索引中的间隙进行锁定，以防止幻影行的插入。
- 默认行级锁
- 采用聚簇索引

#### MYISAM:

缺点:**不支持事务,不支持行级锁(最典型的性能问题,可能长期LOCK),无法崩溃恢复**

很多特性:

- 全文索引

- 压缩

- 空间函数

- 长字段也可以前缀索引

- 延迟更新索引建

  创建表时，如果指定了DELAY KEY WRITE选项,在每次修改执行完成时，不会立刻将修改的索引数据写入磁盘，而是写到内存中的键缓冲区，在清理键缓冲区或者关闭表的时候才会将对应的索引块写入到磁盘。极大地提升写入性能，但是数据库崩溃时会造成索引损坏，需要执行修复操作。

- 压缩表

  若表数据不修改,可以压缩(除非解压,否则不可修改)

  极大减少空间占用,也可以减少磁盘IO,读取数据要解压,但不是事

  记录独立压缩,不用解压表或页

## 表/数据类型优化

### 原则

- 尽可能**小的数据类型**->更少的磁盘,更少的内存,更少的CPU缓存
- 尽可能**简单的数据类型**->整形比字符代价低,字符涉及到排序,字符集等等
- **避免NULL**->**更难优化,索引,统计,比较更复杂;更多的存储空间**
- 有关联操作时,尽量时两者是同一类型,避免隐式转换
- IP地址 实际上就是32位无符号整数,用小数点只是为了方便看,INET_ATON()和INET NTOA()可以用于转换

### 整数

- TINYINT->8,整数范围:-127-128/0~255
- SMALLINT->16
- MEDIUMINT->24
- INT->32
- BIGINT->64

1. **指定是否正数**,可以增加正数范围,但存储消耗不变
2. 指定宽度,如INT(11)无效

### 实数

不只是为存储小数部分，也可以用DECIMAL存储比BIGINT还大的整数。

类型:

- FLOAT和DOUBLE:使用浮点运算进行**近似计算**,**速度会更快**,**存储所需空间也比DECIMAL小**

- DECIMAL:精确小数,**每4个字节存9个数字**。例如，DECIMAL(18,9)小数点两边将各存储9个数字，一共使用**9个字节**:小数点前4 个字节，小数点后 4 个字节,小数点1个字节。

  **注意**:数据范围大的时候,可以考虑使用 BIGINT代替DECIMAL,可以同时避免**用浮点数存储计算不精确**;**DECIMAL精确计算代价高**

### 字符串

#### VARCHAR

**可变长**字符串，比定长类型更节省空间，因为**仅使用必要的空间** (越短的字符串使用越少的空间)

如果MySOL表使用ROW FORMAT=FIXED创建的话，每一行都会使用定长存储，这会很浪费空间

使用**1或2个额外字节记录长度**:如果列的最大长度小于或等于255 字节,则只使用1个字节表示,否则2个字节。一个VARCHAR(10)的列需要11个字节的存储空间。VARCHAR(1000)的列则需要 1002个。

VARCHAR节省了存储空间，对性能也有帮助。但是，UPDATE时行变得比原来更长,页内没有空间可以存储，MyISAM会将**行拆成不同的片段**存储，InnoDB则需要**分裂页**来使行可以放进页内。

InnoDB 更灵活，它可以把过长的 VARCHAR存储为 BLOB

**适用场景**:

- 列的最大长度比平均长度大很多

- 列的更新很少，所以碎片不是问题，

- 使用了像 UTF-8 这样复杂的字符集，每个字符都使用不同的字节数进行存储。

**注意事项**:

使用VARCHAR(5)和VARCHAR(200)存储 hello的空间开销是一样的,但是**更长的列消耗更多的内存**，因为 MySOL 用固定大小的内存块保存内部值。尤其是使用**内存临时表**进行排序或操作时会特别糟糕。在利用磁盘临时表进行排序时也同样糟糕。
所以**最好的策略是只分配真正需要的空间**

#### CHAR

**定长**;

MySQL会**删除末尾空格**;

会根据需要采用空格进行填充以方便比较。

适用场景:

- **很短的字符串**，例如存储Y和N,如果采用单字节字符集需要一个字节，但是 VARCHAR(1)需要两个字节，因为还有一个记录长度的额外字节
- 所有值都接近**同一个长度**。例如，MD5值
- 对于**经常变更**的数据，因为定长不容易产生碎片。

#### BINARY 和 VARBINARY

二进制字符串,存储的是**字节码**而不是字符,填充也不一样;MySQL 填充 BINARY采用的是0(零字节)，在检索时也不会去掉填充值

适用场景:

需要存储**二进制数据**，并且希望 MySQL **使用字节码进行比较**

优势:

- 大小写敏感。
- 每次按一个字节，并且根据该字节的数值进行比较。简单很多，也就更快。

#### BLOB和TEXT

存储**很大的字符串**,分别采用**二进制和字符(有排序规则或字符集)**存储

字符类型: TINYTEXT，SMALLTEXT,TEXT，MEDIUMTEXT，LONGTEXT

二进制类型:TINYBLOB，SMALLBLOB，BLOB,MEDIUMBLOB，LONGBLOB

与其他类型不同，MySQL把BLOB和TEXT值当作独立的对象处理。存储引擎在存储时做特殊处理。

当BLOB 和TEXT值太大时，InnoDB 会使用专门的外部存储区域来进行存储，每个值在行内需要1~4个字节存储指针，外部存储区域存储实际的值。
**排序**:只对每个列的最前 maxsort_length字节做排序。如果只需要排序前面一部分字符，则可以减小max_sort_length的配置，或ORDER BY SUSTRING(column,length)。
MySQL不能将 BLOB和TEXT列全部长度的字符进行索引，也不能使用这些索引消除排序。

### 枚举(ENUM)

可以使用枚举列代替常用的字符串类型。MySQL**存储枚举时非常紧凑**，会根据枚举数量压缩到一个或者两个字节中。内部会将每个值**保存为整数**，并且在表的frm 文件中保存“数字字符串”映射关系的“查找表”。

注意事项:

- **排序根据存储的整数来排序**,除非根据需要的顺序定义枚举类,或查询的时候用FIELD()指定顺序(mysql会无法用索引消除排序)
- 添加或删除枚举值只能ALTER TABLE

**书中关于ENUM 还有其他内容,但是我目前跳过了,用不到**

### 日期和时间类型

- DATETIME
  **范围大**，从 1001 年到 9999 年，精度为秒,格式为YYYYMMDDHHMMSS的整数，与时区无关。**8个字节的存储空间**。

- TIMESTAMP
  从1970年1月1日午夜以来的秒数。**4个字节的存储空间**,因此范围比DATETIME小得多,只能表示从1970年到2038年

  FROM UNIXTIME():时间戳转换为日期，UNIX TIMESTAMP():日期转换为Unix时间戳

  **依赖时区**。

  插人时没有指定值,会默认设置第一个TIMESTAMP列的值为当前时间。

  TIMESTAMP 列**默认为NOT NULL**，这也和其他的数据类型不一样。

注意事项:

**通常尽量使用 TIMESTAMP，空间效率更高**
如果需要存储比秒**更小粒度的日期和时间值**怎么办?可以使用 **BIGINT 类型存储**微秒级别的时间截，或者使用**DOUBLE存储秒之后的小数**部分

### 位(BIT)

书里有,我用不上

### 主键的选择

**原则:**

1. 所有的表主键应该统一,这样在关联的时候可以**避免隐式转换带来的性能问题**,和很难发现的小错误
2. 在满足值的范围的前提下,选择最小的数据类型

各种数据类型比较:

1. **整数类型**: 最好的选择,因为他们**本身很快**,并且**可以使用自增**

   **为什么要自增呢?**

   非自增会占用更多的空间->**更长的长度和页分裂导致**

   拿innodb来说,我们普通索引中排序的只是主键的值,我们**数据本身会根据聚簇索引排序(**一般就是主键),那么我们新增一条数据的时候,然后**根据主键排序,自增主键的话就可以直接放在所有最后**,可以**尽量避免页分裂**和**insert的时候插后面就完事了**,select的时候,有较大可能性数据连在一块,缓存的击中率也比较高

   **如果是随机插入**

   如果要插入的所在页是在硬盘,就**需要先从硬盘读取到内存,也就是会导致大量的随机IO**

   如果数据所在页已经满了,就会出现**页分裂**,会**移动大量数据**,一次页分裂最少改动三个页,而不是一个

   频繁页分裂,会导致**页不规则,数据稀疏**

2. Enum和Set->傻逼才用

3. **字符串类型**

   1. 消耗空间

   2. 速度通常比数字类型慢->尤其是在**Myisam,字符串默认使用压缩索引**,查询会慢的多(最多6倍性能差距)

      随机的就更不能用了,什么uuid(有一定顺序,但是没整数好),md5,就会出现上面说的,**要找到数据位置,所以insert很慢**,并且**频繁页分裂**,,select的时候,**逻辑上在一块的数据也都是分散开的**,**缓存也没啥用了,因为缓存的击中率都是一样的**

#### 针对主键是否自增进行测试



### 表设计

1. **避免太多列**->Mysql读取数据通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列,这个操作代价非常高。
2. 查询**避免关联太多关联表**查询->解析和优化查询会消耗性能
3. 避免过度用枚举->如果不是在末尾添加元素,需要ALTER TABLE
4. 用枚举替代集合列 ->如 is_default set('Y','N) NOT NULL default 'N'
5. **避免 NULL**->更难优化,索引,统计,比较更复杂;更多的存储空间,即使需要使用空值,也可以用'',0替代
6. 适当反范式,即字段冗余
7. 使用的做汇总表(云记账里的余额表)

### ALTER TABLE 优化

mysql 的ALTER TABLE **大部分**(不是全部)操作 都是创建新表->迁移数据->删除旧表实现的

特殊场景:

常用场景的技巧:

1. 先在不提供服务的机器上执行ALTER TABLE,然后和提供服务的数据库切换**(但是数据不一致的问题是怎么解决的呢??)**
2. 人为的去->创建新表,迁移数据,重命名,删除旧表(但是数据不一致的问题是怎么解决的呢??)

注意:如果只是**修改默认值**,语句换一下就不用重建表了

```
mysql> ALTER TABLE sakila.film
-> MODIFY COLUMN duration TINYINT(3) NOT NULL DEFAULT 5;  这个很慢

mysql> ALTER TABLE sakilafilm
-> ALTER COLUMN rental duration SET DEFAULT 5;  //这个很快

```

**其他技巧:直接修改frm文件**->这个没看,风险较大,书里有



## 高性能的索引

### 计算索引成本

书籍:Relational Database Index Design and the Optimizers

### 云记账的索引优化经验

优化流程:

1. 整理出目前的慢sql
2. 分析对应的表结构,整理出索引
3. 根据执行计划,查看索引是否被有效利用
4. 删除无效索引,增加有效索引
   1. 一个sql走两个单一索引,其实是取两个数据集的交集,性能上低于走一个索引
   2. 依据常用的查询条件组合,增加联合索引

**具体案例:**

某个sql的where语句中有多个in值匹配,且查询的字段较多,是要回表的,基于这个场景

```
SELECT 很多列（没有索引覆盖的效果） FROM gl_account_ledger
WHERE customer_id IN (1, 2, 3...)
AND account_set_id IN (1 ,2 ,3...)
AND del_id = '0'
And closing_flag = '1'; 

//del_id和closing_flag的区分度较低
//现有索引:  id ;`uk_period` (`customer_id`,`account_set_id`,`account_period`,`del_id`);`auto_shard_key_customer_id` (`customer_id`)
```

1. 直接查询走全表

   uk_period或auto_shard_key_customer_id中,根据最左匹配原则,因为**有多个in值匹配,实际使用到的所以只有一个**,假设此时不需要回表的话,ref 为 range,但是要回表,且回表代价太大,优化器抽样判断后选择全表查询

2. **添加索引**` KEY `idx_closing_flag` (`account_set_id`,`del_id`,`closing_flag`)`,**同上**

3. **添加索引** `KEY `idx_closing_flag_del_id_customer_id` (`closing_flag`,`del_id`,`customer_id`)`,虽然ref(等值匹配了),但是由于前两列的区分度太低,也没啥用

4. force index(auto_shard_key_customer_id),强制使用customerId,预计扫描行数小于3,效果比其他的好

结论:

1. 根据查询条件,把等值匹配的索引列靠前,索引效果更好
2. 有时候可以人为介入一下索引的选择

### 索引的优点

1. 大大减少了服务器需要扫描的数据量
2. 帮助服务器避免排序和临时表。(因为如B_TREE本身会按照顺序排序)
3. 可以将随机I/0变为顺序I/O。(因为如B_TREE本身会按照顺序排序)
4. 可以避免回表

### 常见索引类型

#### B-Tree

每个索引都会生成一个索引树,按照顺序排序,比父节点小的在左子树,大的在右子树,但是**叶子结点的指针指向的是真正的数据行所在的地址**,并且**叶子结点之间用链表前后串联在一起**,方便进行范围查询

生效的场景

1. 所有索引字段等值匹配
2. 根据最左匹配,只用联合索引的前几个字段精确匹配
3. 根据最左匹配,前几列精确匹配,后一列匹配范围值,但是用于范围匹配的索引列后面的字段就不能走索引了(优化器自己优化的不算)
4. 只查索引字段,也就是覆盖索引,不用回表
5. 因为索引树本就是根据索引列排序的,因此如果用索引字段排序,order by(经过我个人实践,group by的字段顺序也跟联合索引的顺序有关,一致效率就高)也满足排序要求

#### hash索引

因为hash索引是把所有索引列的值hash后生成hashcode实现的,因此使用的时候必须是**所有索引列等值匹配**

hash索引:**hash表+链表实现,key:这一行数据的索引列生成的hashcode,value:链表,里面存指向这一行的指针**

**优点:**索引就存个hash值,也不用排序,结构也很紧凑,所以查起来很快

**缺点:**

1. 存的是hash值,没法排序
2. 要用就必须**所有索引列都作为查询条件**才行
3. 不能范围查找
4. 和hashmap一样,会出现hash冲突,要平衡数组长度,防止数组太长->浪费空间,太短->hash冲突严重 

使用示例:

**前提:存储引擎本身不支持哈希索引**

假设一个字段存储的是URL,并且**需要用它来搜索**,如果要创建索引,要耗费大量的空间,此时就可以手动新增一个索引,使用CRC32函数做哈希

那么我们可以这样查询:

```
CREATE TABLE pseudohash{
id int unsigned NOT NULL auto increment,
url varchar(255) NOT NULL,
url_crc int unsigned NOT NULL DEFAULT 0,
PRIMARY KEY(id)
KEY `crc_url` USING BTREE (`url_crc`)

SELECT id FROM url WHERE url="http://www.mysql.comAND url crc=CRC32("http://www.mysql.com");//使用CRC32函数,用编码后的值进行匹配,即使出现冲突时也可以等值匹配
```

**缺点:**我们要在url被修改的时候**手动去维护url_crc的值**,此时可以选择**手动维护,**也可以采用**触发器**

**注意:**

不要使用 SHA1()和 MD5()作为哈希函数,因为这两个函数计算出来的**哈希值非常长，浪费大量空间，比较时也会更慢**。SHA1()和 MD5()是强加密函数，设计目标是**最大限度消除冲突**，但这里并不需要这样高的要求。**简单哈希函数的冲突在一个可以接受的范围，同时又能够提供更好的性能**
**如果数据表非常大，CRC32() 会出现大量的哈希冲突**，则可以自己实现64 位哈希函数。**这个函数要返回整数**，而不是字符串。一个简单的办法可以使用**MD5()函数返回值的一部分**来作为自定义哈希函数。还可以使用 FNV64() 函数作为哈希函数，可以以插件的方式在任何 MySQL 版本中使用**，哈希值为 64 位，速度快，且冲突比CRC32()要少很多**

#### 空间索引

用来地理数据存储,不如用POSTgreSQL的POSTGIS

#### 全文索引

适用于匹配,搜索,而不是where来查找

### 高性能的索引策略

#### 原则

1. 避免对索引列计算

   ```
   SELECT actor id FROM sakila.actor WHERE actor id + 1 = 5;//索引会失效
   ```

2. 避免对索引列使用函数

   ```
   SELECT ... WHERE TODAYS(CURRENT DATE) - TO DAYS(date_col) <= 10;//索引会失效
   ```
   
3. 在设计索引的时候,不应该只对当前用到的查询,设计最完美的索引,还要考虑到**未来的拓展性**
   如果针对当前查询,设计一个最合适的索引,但是适用性很小,那么后续有新查询时也就无法复用,需要新加索引或优化原索引

#### 前缀索引

```
ALTER TABLE sakila.city_demo ADD KEY (city(7));//语法
```

有时候要**索引很长的字符串**，除了前面说的hash索引，还有别的解决方案么？->**前缀索引**：只索引字符串前面的字符，大大节约空间，提升索引效率，**但是如果太短，索引的效果会降低**，类似于hashmap的散列表数组太短会导致更多hash冲突

**那么怎么选择前缀索引的长度呢？**

1. 首先针对索引列分组，看看数据分布①
2. 然后取索引列的前缀进行分组
3. 调整前缀长度，直到分布和①差不多，就选这个长度

```
SELECT COUNT(*) AS cnt,city FROM city_demo GROUP BY city ORDER BY cnt DESC LIMIT 10;//①
SELECT COUNT(*) AS cnt，LEFT(city，7) AS pref FROM city_demo GROUP BY pref ORDER BY cnt DESC LIMIT 10;//
```

```
SELECT COUNT(DISTINCT city)/COUNT(*) FROM sakila.city demo;

SELECT COUNT(DISTINCT LEFT(city，3))/COUNT(*) AS sel3,
COUNT(DISTINCT LEFT(city，4))/COUNT(*) AS sel4,
COUNT(DISTINCT LEFT(city，5))/COUNT(*)AS sel5,
COUNT(DISTINCT LEFT(city，6))/COUNT(*)AS sel6,
COUNT(DISTINCT LEFT(city，7))/COUNT(*)AS sel7FROM sakila.city_demo;

//根据第二个sql选出合适长度的前缀
```

但是上面两个方法中，如果用第二个方法，选出了一个长度，是不够的，需要再根据第一个SQL，看**数据的分布是否均衡**，如果差异很大，说明这个长度的前**缀索引的选择性不够,那么**需要**增加长度**

**优点和缺点:**

优点: 占用空间更小,查询速度更快

缺点: **无法使用前缀索引做ORDER BY,GROUP BY**

#### 联合索引

**索引合并:**mysql5.0以后,若针对两个字段,**分别建立索引**,但是查询条件中对两个等值匹配,用and连接,此时执行计划中可以看到索引列的选择采用如下方式:

```
Using union(索引1,索引2); Using where
表示对两个索引分别等值匹配,然后union,即取并集
出现索引优化的策略往往表示索引列的选择很垃圾
```

上面只是一种例子,**索引合并策略可能会对结果取并集/交集**,然后排序,合并,会**消耗大量的CPU资源和内存资源**,并且这些成本**优化器是识别不到**的,此时应该采用**联合索引替代多个单列索引**

##### 选择索引列的顺序

- 不需要考虑排序分组的话,把**选择性最高(即能筛掉的越多就像云记账的customerId)**,或**运行次数最多(即用的最频繁)**的放前面

**注意特殊情况:**当**索引列的选择性很低**,并且数据量很大的时候(也就是索引用处不大),可能会对性能有很大的波动

示例:

假设以下场景:

在线约会网站，用户信息表包括**国家、地区、城市、性别、眼睛颜色**，等等。网站支持这些字段的**各种组合来搜索**用户，还必须允许根据最后在线时间、用户评分等对用户进行**排序**,如何设计索引满足上面的复杂需求呢?

**分析:**

1. **根据经验法则(选择性和频率)**,国家,性别这两列的**频率很高**,**虽然他俩选择性很低**,但是加上也没有坏处,可以放在前面,即使搜索的时候没有这俩字段,我们可以**手动用sex in ('f','m')的方式强行满足最左匹配,但in()列表太长不可以这样,用到in()的字段也不可以太多,不然会很大的降低优化器性能**

##### 多个范围查询

写sql的时候常常会碰到下述问题:

```
WHERE eye_color IN ('brown',blue'hazel') 
AND hair_color IN('black','red','blonde','brown') 
AND sex IN('M'，F')
AND last_online > DATE SUB(NOW()，INTERVAL 7 DAY)//最近登录时间
AND age BETWEEN 18 AND 25
```

1. 尝试写sql的时候把某些范围查询用in代替
2. 上述有两个范围查询,但是仍然希望他们很快,有办法么?->**没有!!**只有如下方案
   1. age放入索引中,last_online字段做业务上的处理,新增active列:七天内登录则为1,否则为0,查询的时候用in(0,1)->对应的索引:(active, sex, country, age),如果需要精确数据,再将last_online放到where子句中
   2. 针对不同的查询创建多个索引:(active, sex,country,age)，(active,country, age)，(sex, country, age)和 (country, age),**但不建议**


#### 聚簇索引

不是索引类型,而**是存储方式**->真正的**数据行就在索引树的叶子结点**,即数据和索引是在一块的,**注意,不是叶子结点引用数据行的指针,那样就成了B-Tree了,而是数据行本身就在叶子结点!!**除了数据行,innodb还存了**事务ID**、用于事务和 MVCC的**回滚指针**
**因为数据行就一个,所以一张表就一个聚簇索引**

以Innodb举例:

聚簇索引选择的列一般就是主键,我们手动建立的索引就是二级索引,叶子结点存储的是**主键的值(不是指针噢,好处就是数据存储位置如果改变,不用去维护二级索引树)**

**优点:**

- 可以把相关数据保存在一起。例如实现电子邮箱时，可以根据用户ID来聚集数据文样**只需要从磁盘读取少数的数据页**就能获取某个用户的全部邮件。如果没有使用聚簇索引，则每封邮件都可能导致一次磁盘 I/O。
- 数据访问更快。**聚簇索引将索引和数据保存在同一个 B-Tree** 中，因此从聚簇索引中读取数据通常比在非聚簇索引中查找要快(**即用主键查很快**)。

**缺点:**

1. 聚簇索引在**需要频繁I/O的时候,效率最大**,也就是数据存储在磁盘->数据都放在内存的就不适合聚簇索引

2. **插入速度严重依赖于插入顺序**->用**自增主键**的方式是最好的

   如果不是按照主键顺序加载数据，那么在加载完成后最好使用**OPTIMIZE TABLE**命令重新组织一下表**(整理碎片化空间)**

3. 更新聚簇索引列的代价很高，会强制InnoDB 将**每个被更新的行移动到新的位置**->所以**不要随便更改主键**

4. 插入新行，或者主键被更新导致需要移动行的时候，可能面临**页分裂**的问题。当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将**该页分裂成两个页面来容纳该行**，这就是一次页分裂.**页分裂会导致表占用更多的磁盘空间**。

5. 聚簇索引可能导致全表扫描变慢，尤其是**行比较稀疏**，或者由于页分裂导致**数据存储不连续**的时候。

6. 二级索引可能比想象的要更大，因为**叶子节点包含了引用行的主键列**

7. 二级索引可能要两次查找(就是**回表**,找到主键后,再到聚簇索引树查找数据行)

#### 覆盖索引

即用到的**索引的索引列已经包含所需字段**,**无需回表**

好处:

1. 用普通索引时,**只需要读取索引数据**,**不用回表去查询数据,然后读取整条数据行**,可以减少缓存负载,因为数据拷贝会花很大消耗
2. IO次数少的多,前面说过mysql在**索引树上每向下一层都是一次IO**,这个过程少了回表和主键树的查找,少了很多IO

实例:

```
有的时候查询列过多,不方便使用覆盖索引,可以采用如下形式->延迟索引
SELECT * FROM 
products JOIN
(SELECT prod id FROM products WHERE actor='SEAN CARREY' AND title LIKE %APOLLO%) 
AS t1 0N (t1.prod_id=products.prod_id)
这种情况适用于子查询可以过滤掉很多数据的情况,也就是回表的开销很大的情况下,否则效率可能还不如普通查询
```

#### 通过索引排序

数据有序有两种方式: **mysql对数据排序**  **按照索引顺序读取数据**

**必要条件**:**只有当索引的列顺序和 order by顺序一致,且所有列的排序方向(正序倒序)都一致时,并且where子句和order by 子句加起来满足最左匹配(比如索引A,B,C,where A='a' order by B,C或order by A,B,C),mysql才可以使用索引顺序读取数据**

**性能:**

所有索引列包含查询列,那么查询起来是很快的,否则每根据索引找到一条数据都要回表,就会比较慢,因此一个索引**既满足查询又满足排序**是最好的

#### 压缩索引/前缀压缩索引

会**使用更少的空间,但是大多数情况会牺牲一些性能**

有兴趣可以详细了解

#### 冗余和重复索引

**外部工具**:pt-duplicate-key-checker可以分析表结构找出冗余和重复索引

**定义:**

什么是冗余索引呢,(A)  (A,B)这就是冗余索引,因为后者已经包含了前者了,但是**冗余索引是有存在的必要的**

什么是重复索引呢,unique(A)  index(A) 从功能上来说前者完全替代后者,应该**立刻删除重复索引**的

**大多数情况下都不需要冗余索引**，应该尽量**扩展已有的索引**而不是创建新索引。但也有时候**出于性能方面的考虑需要冗余索引**，因为扩展已有的索引会导致其变得太大，从而影响其他使用该索引的查询的性能。

示例一:

如果在整数列上有一个索引，现在需要额外增加一个很长的 VARCHAR 列来扩展该索引，性能可能会急剧下降。特别是有查询把这个索引当作覆盖索引，或者这是MyISAM表并且有很多范围查询 (由于MyISAM的前缀压缩)的时候

```
这个表有1000000行，对每个 state id值有20000条记录。
state id列有一个索引，查询名Q1 :
mysql> SELECT count(*) FROM userinfo WHERE state id=5;
查询名Q2 :
mysql> SELECT state id, city, address FROM userinfo WHERE state id=5;
提升该查询性能的最简单办法就是扩展索引为(state id，city，address):
索引扩展后，Q2 运行得更快了，但是 Q1 却变慢了(为什么会变慢???)。如果我们想让两个查询都变得更快就需要两个索引

书中有具体的效率比对,有必要看一下
```

示例二:

存在索引(A)  (A,B)

但是有查询语句,where A=1 order by B

**注意:**索引数量越多**,维护的成本越高**,insert和update的**Qps也就越低**,需要在两者之间进行取舍



#### 索引和锁

结论:索引可以让查询锁定更少的行,消耗更小的性能

原因:

1. InnoDB 只有在**访问行的时候才会对其加锁**，而索引能够**减少访问的行数**，从而**减少锁的数量**
2. 虽然InnoDB 的行锁效率很高内存使用也很少，但是锁定行的时候仍然会带来额外开销
3. 锁定更多的行会增加锁争用并减少并发性
   这只有当InnoDB 在**存储引擎层的时候(也就是用索引查找)才有效**,如果索引无法过滤掉无效的行，InnoDB 检索到数据**并返回给服务器层后服务器才能应用WHERE子句**。这时已经无法避免锁定行了:InnoDB**已经锁住了这些行**，到适当的时候才释放。在MySOL 5.1之后中，InnoDB 可以在服务器器端用where子句过滤掉行后就释放锁，以前不行

```
SELECT actor id FROM sakila.actor WHERE actorid < 5 AND actor_id <> 1 FOR UPDATE;//
actorid < 5用到了索引 actor_id <> 1没用到索引,所以实际上锁定了5行,而不是4行
```

#### 排序的优化

**问题:**筛选出来的**数据集量很大**怎么办

**解决方案:** 针对**排序字段增加索引**

```
SELECT <cols> FROM profiles WHERE sex='M' ORDER BY rating LIMIT 10; 
增加索引 (sex,rating),这个查询同时使用了ORDER BY和LIMIT，如果没有索引的话会很慢
```

**问题:**需要**翻页**,并且**翻的页数在很后面**

```
mysql> SELECT <cols> FROM profiles WHERE sex='M' ORDER BY rating LIMIT 100000, 10;
```

1. **索引层面基本没办法优化**,**反范式化、预先计算和缓存**可能是仅有策略

2. **限制用户翻页数量**,用户一般不会很在意这么后面的数据

3. **避免mysql回表扫描**那些需要丢弃的行

   ```
   mysql> SELECT <cols> FROM profiles INNER JOIN 
   (SELECT <primarykey> FROM profilesWHERE x.sex='M' ORDER BY rating LIMIT 100000，10->) 
   AS x USING (<primarykey>);
   ```

### 维护索引和表-基本没看

#### 找到并修复损坏的表

运维干的活,没看,直接跳过了

#### 更新索引统计数据

在Mysql中,统计信息是存储在存储引擎层的

```
API1:records_in_range()，向存储引擎传入两个边界值 获取这个范围大概多少条记录。对于MyISAM，该接口返回精确值，对于InnoDB则是一个估算值
API2:info()，该接口返回各种类型的数据，包括索引的基数 (每个键值有多少条记录)
```

优化器会根据以上API计算执行成本,当API1无法提供准确的信息,则会用API2得到统计数据,若API2得到的数据不准确,会影响优化器的执行计划选择
可以通过**ANALYZE TABLE来重新生成统计信息**
表首次打开,ANALYZE TABLE命令,表的大小有较大变化,会**重新生成统计信息**

就了解到这里,也是运维干的活

#### 减少索引和数据的碎片

很前面说的页分页有关系

**索引的碎片化**

B-Tree 需要**随机磁盘访问才能定位到叶子页**，所以随机访问不可避免。如果叶子页在物理分布上是**顺序且紧密的**，那么查询的性能就会更好。否则范围查询、索引覆盖扫描等操作，速度可能会降低很多倍，对于索引覆盖扫描这一点更加明显。

**数据的碎片化**

运维干的活,看书

### 总结

索引的设计:

1. **单行访问是很慢**的。特别是在机械硬盘存储中 (SSD 的随机I/O 要快很多)。如果服务器从存储中**读取一个数据块只是为了获取其中一行**，那么就浪费了很多工作。最好**读取的块中能包含尽可能多所需要的行**。使用**索引可以创建位置引用以提升效率**
2. **顺序访问范围数据很快**,这有两个原因。第一,**顺序IO 不需要多次磁盘寻道**所以比随机 I/0 要快很多(特别是对机械硬盘)。第二，如果服务器能够按需要顺序读取数据，就**不需要额外的排序操作**，并且 GROUP BY查询也**无须再做排序和按组进行聚合计算**了。
3. **索引覆盖查询是很快**的。如果一个索引包含了查询需要的所有列，那么存储引擎就**不需要再回表查找行**。这避免了大量的单行访问，而上面的第 1 点已经写明单行访问是很慢的。

上面这些话很难理解,但是不妨碍得出以下原则:以下是**自己的理解**

1. 主键的选择,自增整数,可以防止碎片化
2. 索引的设计,除了查询,最好兼容排序,可以顺序访问数据
3. 索引的设计,尽量覆盖查询,可以防止回表

## 查询性能优化

#### 基本概念:

一个查询由一系列子任务组成,要优化查询,分成两步

1. 去除一些子任务
2. 减少一些子任务的执行次数
3. 子任务执行的更快

查询的生命周期大致分为 :从客户端，到服务器，然后在服务器上进行**解析**，**生成执行计划，执行**，并返回结果给客户端,其中“执行”是整个生命周期中最重要的阶段，这其中包括了大量为了**检索数据到存储引擎的调用以及调用后的数据处理**，包括排序、分组等。

#### 慢SQL基础

**基本原因:访问数据远超过需要的数据**

**解决方案:**

1. **检索的数据远超过需要的数据**,可能是行,也可能是列
2. **分析的数据远超过需要的数据**

##### 请求数据过多

**写sql原则(很基础):**

1. 只查询需要的数据,比如limit 10

2. select 选择具体的列,而不是select *,(这个具体考虑,可以减少代码维护成本)

3. 不要重复查询相同数据

   在用户评论的地方需要查询用户头像的 URL，那么用户多次评论的时候，就会反复查询这个数据。比较好的方案:**缓存**

##### 检索数据过多

最简单的三个指标,**以下三个指标都会记录到mysql的慢sql日志**:

- 响应时间
  **服务时间和排队时间之和**。排队时间最常见和重要的等待是 I/O 和锁等待，但是实际情况更加复杂。

  可以通过**快速上限估计**估算响应时间,该方法在在上面计算索引成本的书里面有

- 扫描行数

- 返回行数

**扫描行数和返回行数:**

很有用,越接近越好但是关联查询的时候,如果有一对多的关系,可能会扫描多行但只返回一行

**扫描的行数和访问类型**
访问类型:EXPLAIN语句中的 type 列。访问类型有很多种，从**全表扫描到索引扫描、范围扫描、唯一索引查询、常数引用**等。这里列的这些，速度是**从慢到快**，**扫描的行数从小到大**。
如果查询**没有合适的访问类型**，那么解决的最好办法通常是**增加一个索引**。索引让 MySQL 以最高效、扫描行数最少的方式找到记录。

Extra 列出现Using Where的三种情况,由好到坏:

1. 所有列完全满足最左匹配,完全走索引
2. 用索引筛选了数据范围,然后用where精确筛选->Extra 出现Using index
3. 没用索引->Extra 出现Using Where

#### 重构查询

##### 复杂查询还是简单查询

可以把一个复杂查询拆分成多个简单查询

**以前误区:**

强调在数据库层完成尽可能多的工作，因为以前认为一次 网络通信、查询解析和优化是一件代价很高的事情。

但在Mysql不适用:

1. 连接/断开连接很轻量,小的查询很高效
2. 现代网络查询很快,运行多个小查询不会有什么影响

##### 切分查询

**背景:**一次查询/删除/新增大量数据

**问题:**一次性**锁住大量数据**,因为数据量多,可能会**占满整个事务日志,占用大量系统资源,阻塞其他操作**

**解决方式:**拆分成小的,拿定期删除数据来说,每次删除10000条数据,允许的话,每次删完休眠一会可以把数据库的压力分散开,减少其他事务的影响和锁的持有时间

##### 分解关联查询

背景:一个关联查询分解成多个简单查询

好处:

- 缓存效率更高:

  1. 应用缓存:若应用查询缓存了第一个查询,则可以跳过第一个查询,减少查询次数

  2. Mysql缓存:关联的多个关联表中,有一个表变化了就无法使用缓存,单表查询的话若某个表没变化,基于该表的查询可以使用缓存

- 单个查询可以减少锁的竞争
- 应用层,可以更容易对数据库拆分
- 拆分后用In()的方式,可以让Mysql按照id顺序进行查询,可能更高效.???**后面回来补充**

#### 一个查询的整体流程

##### 基本概念

1. 客户端发送查询
2. 服务器检查缓存,若命中则直接返回
3. SQL解析,预处理,**优化器生成执行计划(最复杂)**
4. 调用存储引擎API执行
5. 返回结果

##### Mysql客户端/服务端的通信协议

客户端和服务端的通信协议是半双工的:在任何一个时刻，要么服务器向客户端发送数据，要么是由客户端向服务器发送数据，两者不能同时发生。所以，我们无法也无须将一个消息切成小块独立来发送。
**好处:** 通信简单快速

**坏处:没法进行流量控制**。一旦一端开始发生消息，另一端要接收完整个消息才能响应它。这就像来回抛球: 在任何时刻，只有一个人能控制球，而且只有控制球的人才能将球抛回去(发送消息)。
客户端用一个单独的数据包将查询传给服务器。这也是为什么当查询的语句很长的时候，参数max_ allowed_ packet 很重要。一旦客户端发送了请求，它能做的事情就只是等待结果了。
相反的，一般服务器响应给用户的数据通常很多，由多个数据包组成。当服务器开始响应客户端请求时，客户端必须完整地接收整个返回结果，而不能简单地只取前面几条结果，然后让服务器停止发送数据。这也是必要的时候一定要在查询中加上LIMIT限制的原因。

------

注:**多数连接Mysql的库函数是在客户端上的**

库函数可以   方式一:**接受服务器的所有数据并缓存到内存(默认)**;也可以方式二:**逐行获取需要的数据**

但是Mysql**服务器要等所有数据都发送给客户端才能释放资源,**所以 **方式一可以减少服务器压力**,查询早点结束,早点释放服务器资源

库函数获取数据看起来像是从Mysql服务器获取,其实是从**库函数的缓存**里面取的

**问题:**返回的数据集很大时,**使用方式一,然后从缓存取数据,会花很多时间和内存来存储结果集**,这种情况下不使用缓存,而是方式二可以大大减少内存消耗

缺点:也就是上面说的,会让交互时间延长,占用资源

我们可以在应用中,**连接mysql的参数中指定参数**,使得整个连接返回的数据集都不会缓存

##### 查询连接状态

任意一个Mysql的连接,任何时刻都有一个状态,可以使用 SHOW FULL PROCCESSLIST 查看当前状态

SLEEP:等待客户端发送新消息

QUERY:正在执行查询或正在发送结果

LOCKED:正在等待表锁. 注意:存储引擎级别实现的锁不会展示出来,如Innodb的行锁

Analyzing and statistics: 线程正在收集存储引擎的统计信息，并生成查询的执行计划。

Copying to tmp table [on disk] : 线程正在执行查询，并且将其结果集都复制到一个临时表中，这种状态一般是在做GROUP BY/文件排序/UNION。如果有“on disk"标记，那表示MySQL正在将一个内存临时表放到磁盘上。

Sorting result :线程正在对结果集进行排序。

Sending data:多种情况->在多个状态之间传送数据/在生成结果集/在向客户端返回数据。

**用处:**

快速了解当前Mysql的状态->在一个繁忙的服务器上，可能会看到大量不正常的状态，例如statistics正占用大量的时间,说明某个地方有异常了，可以通过书中第3章的一些技巧来诊断。

##### 查询缓存

**解析一个查询语句之前**,且**查询缓存的开关打开**,mysql会先检查缓存是否命中(通过**大小写敏感的哈希查找**实现)

若缓存命中,会**校验一下权限,**若权限没问题,直接返回数据

##### 查询优化处理(很长很长)

- 语法解析器和预处理
  两个步骤都是校验语法的,预处理还会校验权限

------

###### **优化器**

**原理:**为一个查询列举出多个执行计划的成本,最终选择成本最小的那个

**成本影响因素:**每个表或索引的页面个数、索引的基数（索引中不同值的数量）、索引和数据行的长度、索引分布情况。注意：评估成本时不考虑缓存，假设每次读取数据都需要一次磁盘IO

**导致成本计算错误的原因：**

- 用来评估成本的统计信息不正确：如前面章节：**更新索引统计数据** 中提到的知识
- 成本估算不准确。示例：由于每次读取数据都假设需要一次磁盘IO，但是如果这些数据已经存在于内存，那么实际成本会小的多
- Mysql的最优和用户理解的不一致。示例：用户希望时间短，但Mysql基于它模型选择成本最小
- Mysql不考虑其他并发的影响
- Mysql有些时候不根据成本来优化，有时会根据规则。示例：使用全文搜索的MATCH（）语句，那么Mysql一定尝试使用全文索引，即使用别的索引更快
- 用户自己写的存储过程或自定义函数，Mysql不会考虑成本
- 无法估算所有可能的执行计划，可能会错过最优计划

------

###### **优化策略：**静态优化 动态优化

**静态优化：**对解析树分析并优化，通过逻辑运算，把**where条件转换成另一种等价形式**（离散数学），它**不依赖于数值且一直有效**，也就是说优化完以后的结果，后面调用同一个语句但是参数不同，也能直接拿来用（就像静态编译，编译完可以到处用）

**动态优化：**和上面相反，跟where条件中参数的值，索引对应的数据行数等有关，所以每次执行都要重新评估（动态编译）

------

###### **优化类型**

- **调整关联表的关联顺序**

- **外连接转化为内连接** 以下SQL就可以转化

  ```
  select * from a 
  left join b 
  where b.age=...
  ```

- **等价变换**  如5=5 and a>5 被改写为 a>5

- **优化表达式：count() min() max()**

  **索引和列是否可为空**可以帮助优化这类表达式(只有不为null，才可以起到优化效果 ？？？)

  如min（）：mysql可以直接获取索引最左端的第一行数据

  max（）：索引最右端记录

  count（*）:不带where条件，Myisam有一个专门的变量存放表行数

  假设可以成功优化，那个这个**表的查询可以从执行计划移除，用一个常数代替**，那么他对应的**成本也是常数级别**。

- 把某些**查询表达式变成常数**

  - 上面max（）等语句可以成功优化的话，就是一种情况

  - **查询条件中使用索引，且参数为常数**，那么mysql可以在查询开始时先找到这些值，那么优化器可以把它转换为常数表达式

    ```
    select * from a
    inner join b using(id)
    where a.id=1//该语句的执行计划中，ab表的查询都可以转化为常数
    ```

    以上语句分为两步

    1. 因为id有**主键索引**，从where a.id=1确定a表查询结果的行数为1

    2. on子句通过using（id）来连接，因此也可以**通过索引确定子查询的数据行数**

- **覆盖索引**

  索引列已包含查询字段，mysql可以用索引返回需要数据

- 对子查询优化

  对子查询优化，减少多个子查询时对数据的访问次数

- 提前终止查询

  典型例子：**limit 0，10**  和  **where id<0 and id=0（explain语句可以看到在优化阶段就终止）**

- 等值传播

  典型例子 

  ```
  select * from a
  inner join b on b.id=a.id
  where a.id=1   
  //把a.id的等值匹配传递给了b.id上->
  select * from a
  inner join b on b.id=1
  where a.id=1
  ```

- 对In()的优化

  In()等价于多个or条件的子句,但是mysql不是这么做的,它将in()列表中的值排序,然后二分查找进行匹配,复杂度由O(n)->O(log n)

- 等等等等,书中没有继续列举

###### 多表查询的关联过程

以union为例:

union查询:将一系列的单个查询放到临时表,然后从临时表读取出所有数据

**Mysql执行关联表的策略(所有的查询都是以下流程):**

MySQL**先在一个表中循环取出单条数据**，然后**再嵌套循环到下一个表中寻找匹配的行**，依次下去，直到找到所有表中匹配的行为止。然后从每个表的行中返回需要的各个列。**Mysql尝试在最后一个关联表中找到所有匹配的行，如果最后一个关联表无法找到更多的行以后，MySQL返回到上一层次关联表，看是否能够找到更多的匹配记录，依此类推迭代执行(也就是等价于左连接,以外表为主,在遇到右外连接的时候会转化成等价的左外链接)**。

```
SELECT tbl1. col1, tbl2.col2
FROM tbl1 
LEFT OUTER JOIN tbl2 USING( col3)
WHERE tb11. co11 IN(5,6);
```

![](/Users/wzw/Desktop/assets/20230627223051.png)

看上图的顺序是,**先从左到右,再从上到下**

![image-20230704203119503](../../../Desktop/assets/image-20230704203119503.png)

因此Mysql的执行计划如下所示

![image-20230704204618380](../../../Desktop/assets/image-20230704204618380.png)

###### 多表查询是怎么优化的

**调整关联顺序**

注意:**STRAIGHT JOIN 可以强行指定执行计划的关联顺序**

```
示例: 
前提:actor表200条,film表951条数据,且使用的是inner join,即使调整顺序,结果是等价的(当后面表依赖于前面表的结果时,顺序就不可改变,如左链接或一些子查询)

SELECT film.film id, film.title, film.release_year, actor.actor _id,
actor.first_name, actor.last_name
FROM sakila. film
INNER JOIN sakila.film_actor USING(film_id)
INNER JOIN sakila.actor USING(actor_id);

设想: Mysql先查询film->film_actor->actor
结果:从explain可以看出先actor->film_actor->film,因为从actor开始仅需要关联200行数据
且从执行成本看,从1154减少到了241(执行成本就是磁盘IO的次数)
```

**问题:**Mysql是怎么得到预估成本最小的顺序呢?->**遍历**每一种可能的顺序

**问题:**如果关联的表数量很多呢?遍历每一种顺序,也就是**n的阶乘**(10✖️9✖️8....),数量太多怎么遍历?->当n大于optimizer_ search_depth(可配置),会选择**贪婪搜索**

------

**对排序优化**

当**无法使用索引排序**时,则会使用**文件排序**:**数据少于排序缓冲区时使用内存"快速排序",多时把数据分块,每块"快速排序",把结果放在磁盘,最后合并并返回结果**

排序算法:

