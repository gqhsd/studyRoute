# 数据结构(java为例)

## 1. hashmap

1. jdk1.7->1.8的优化
   **hash算法**:  1.7的hash算法是4次移位后异或;1.8是高16位和低16位异或,保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销

   **引入红黑树**:

   **链表的插入方式**:1.7是头插法,,1.8是尾插法

   **rehash过程**:

   ![img](https://pic2.zhimg.com/80/a285d9b2da279a18b052fe5eed69afe9_1440w.png)

   只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，**省去了重新计算hash值的时间**，而且同时，**由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了**

   **旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置**

   **线程安全**:1.7会出现resize()的过程中会出现闭环,1.8不会,但是线程也不安全

2. 注意点:

   取模运算:通过h & (table.length -1)来得到该对象的保存位,hashmap长度总是2的n次方，这是HashMap在速度上的优化。当length总是2的n次方时，h& (length-1)运算等价于对length取模，也就是h%length，但是&比%具有更高的效率。

## 2.concurrenthashmap

比较详细(1.6为例https://blog.csdn.net/justloveyou_/article/details/72783008?spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-5.pc_relevant_default&utm_relevant_index=10)

1. 读到的数据为null的时候(说明有指令重排序:初始化HashEntry时发生的指令重排序导致的，也就是在HashEntry初始化完成之前便返回了它的引用。这时，JDK给出的解决之道就是加锁重读)会用到锁
2. 快速失败迭代器和弱一致迭代器的区别
3. remove的时候不是像普通链表一样更改一下next值,而是之后的所有entry克隆并拼回前面去,因为除了value，其他 所有属性都是用final来修饰的，这意味着在第一次设置了next域     之 后便不能再改变它，取而代之的是将它之前的节点全都克隆一次。至于entry为什么要设置为不变性，这跟不变性的访问     不需要同步从而节省时间有关
4. size方法过程,循环累加每个房间的修改次数和元素个数,如果和上次没变化,返回累加的元素个数,否则继续,超过尝试阈值,每个房间加锁,再累加(乐观锁转悲观锁)
5. 扩容是段内扩容(1.7)
6. 读操作不需要加锁的奥秘在于以下三点
   - **用HashEntery对象的不变性来降低读操作对加锁的需求；**
   - **用Volatile变量协调读写线程间的内存可见性；**
   - **若读时发生指令重排序现象，则加锁重读；**

	7. 为什么要用synchronized，cas不是已经可以保证操作的线程安全吗？
		原因：
	CAS也是适用一些场合的，比如资源竞争小时，是非常适用的，不用进行内核态和用户态之间的线程上下文切换，同时自旋概率也会大大减少，提升性能，但资源竞争激烈时（比如大量线程对同一资源进行写和读操作）并不适用，自旋概率会大大增加，从而浪费CPU资源，降低性能
	
	7. clear操作只是把ConcurrentHashMap中所有的桶置空，每个桶之前引用的链表依然存在，只是桶不再引用这些链表而已，而链表本身的结构并没有发生任何修改。因此，正在遍历某个链表的读线程依然可以正常执行对该链表的遍历。
	
	关于put操作的,如果需要插入一个新节点到链表中时会在链表头部插入这个新节点，此时链表中的原有节点的链接并没有被修改。也就是说，插入新的健/值对到链表中的操作不会影响读线程正常遍历这个链表。
	
	删除节点C之后的所有节点原样保留到新链表中；删除节点C之前的每个节点被克隆到新链表中(它们在新链表中的链接顺序被反转了)。因此，**在执行remove操作时，原始链表并没有被修改，也就是说，读线程不会受同时执行 remove 操作的并发写线程的干扰。**
	
 9. 所有执行写操作的方法（put、remove和clear）在对链表做结构性修改之后，在退出写方法前都会去写这个count变量；所有未加锁的读操作（get、contains和containsKey）在读方法中，都会首先去读取这个count变量

## CAS(乐观锁)

ABA问题:

如果判断的时候虽然值是一样的,但是可能还是改动过的,如果是引用类型,里面的成员变量可能变更过?

->增加版本号,每次变更后修改版本号,如果版本号变更就判断为修改过



## 自旋锁

使用场景:锁的竞争不激烈,且占用锁的时间很短

原理:会让等待的线程进入自旋操作(让线程做无用功),防止等待线程的两次上下文切换.



## 适应性自旋锁

jdk1.5这个限度是一定的写死的，在1.6引入了适应性自旋锁->根据上次这个对这个锁用的自旋时间和锁的拥有者的状态

如果平均负载小于CPUs则一直自旋

如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞

如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞

如果CPU处于节电模式则停止自旋

自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差）

自旋时会适当放弃线程优先级之间的差异

## Synchronized

Synchronized是非公平锁。 Synchronized在线程进入ContentionList时，等待的线程会先尝试自旋获取锁，如果获取不到就进入ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占OnDeck线程的锁资源。



## 偏向锁

Java偏向锁(Biased Locking)是Java6引入的一项多线程优化。
偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。
如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。












